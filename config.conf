# CyberPatriot Linux Auto Configuration

# AI API Configuration
# For AI integration, set the appropriate API key.
# Preferred: NVIDIA Integrate â€” set `NVIDIA_API_KEY`.
# Also supported: Google Gemini (`GEMINI_API_KEY` or `GOOGLE_API_KEY`) and legacy OpenRouter (`OPENROUTER_API_KEY`).
# Example (NVIDIA): NVIDIA_API_KEY="sk-your_key_here"
NVIDIA_API_KEY=""

# Model to use for README parsing. Prefix with provider/ to select provider.
# Examples:
#  - NVIDIA Integrate: nvidia/google/gemma-3n-e4b-it
#  - Google Gemini: google/gemini-3-pro-preview
OPENROUTER_MODEL="nvidia/google/gemma-3n-e4b-it"

# Ollama local server (optional)
# To use a locally-hosted Ollama server (running on your host machine),
# set the model prefix to "ollama/" in OPENROUTER_MODEL and set OLLAMA_URL.
# Example: OPENROUTER_MODEL="ollama/llama2" and OLLAMA_URL="http://192.168.1.100:11434"
OLLAMA_URL=""

# NVIDIA Integrate API (optional)
# To use NVIDIA Integrate, set OPENROUTER_MODEL="nvidia/<model>" and set NVIDIA_API_KEY
# Example: OPENROUTER_MODEL="nvidia/google/gemma-3n-e4b-it" and NVIDIA_API_KEY="sk-..."
# To enable streaming responses set NVIDIA_STREAM="true"
NVIDIA_API_KEY=""
NVIDIA_STREAM="false"

# Log level: 0=DEBUG, 1=INFO, 2=WARN, 3=ERROR, 4=SUCCESS
LOG_LEVEL=1
